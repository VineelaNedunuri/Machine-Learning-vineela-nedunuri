{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI_category_normal range</th>\n",
       "      <th>BMI_category_obese (class I)</th>\n",
       "      <th>BMI_category_obese (class II)</th>\n",
       "      <th>BMI_category_obese (class III)</th>\n",
       "      <th>BMI_category_overweight</th>\n",
       "      <th>BMI_category_underweight</th>\n",
       "      <th>BP_category_elevated</th>\n",
       "      <th>BP_category_hypertension stage I</th>\n",
       "      <th>BP_category_hypertension stage II</th>\n",
       "      <th>BP_category_normal</th>\n",
       "      <th>gender_Men</th>\n",
       "      <th>gender_Women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   0  50.0            1     1      0     0       1       0   \n",
       "1   1  55.0            3     1      0     0       1       1   \n",
       "2   2  52.0            3     1      0     0       0       1   \n",
       "3   3  48.0            1     1      0     0       1       1   \n",
       "4   4  48.0            1     1      0     0       0       0   \n",
       "\n",
       "   BMI_category_normal range  BMI_category_obese (class I)  \\\n",
       "0                          1                             0   \n",
       "1                          0                             1   \n",
       "2                          1                             0   \n",
       "3                          0                             0   \n",
       "4                          1                             0   \n",
       "\n",
       "   BMI_category_obese (class II)  BMI_category_obese (class III)  \\\n",
       "0                              0                               0   \n",
       "1                              0                               0   \n",
       "2                              0                               0   \n",
       "3                              0                               0   \n",
       "4                              0                               0   \n",
       "\n",
       "   BMI_category_overweight  BMI_category_underweight  BP_category_elevated  \\\n",
       "0                        0                         0                     0   \n",
       "1                        0                         0                     0   \n",
       "2                        0                         0                     0   \n",
       "3                        1                         0                     0   \n",
       "4                        0                         0                     0   \n",
       "\n",
       "   BP_category_hypertension stage I  BP_category_hypertension stage II  \\\n",
       "0                                 1                                  0   \n",
       "1                                 0                                  1   \n",
       "2                                 1                                  0   \n",
       "3                                 0                                  1   \n",
       "4                                 0                                  0   \n",
       "\n",
       "   BP_category_normal  gender_Men  gender_Women  \n",
       "0                   0           1             0  \n",
       "1                   0           0             1  \n",
       "2                   0           0             1  \n",
       "3                   0           1             0  \n",
       "4                   1           0             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1= pd.read_csv('../Labb/data/new_dataset1.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI</th>\n",
       "      <th>gender_Men</th>\n",
       "      <th>gender_Women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   0  50.0    110     80            1     1      0     0       1       0   \n",
       "1   1  55.0    140     90            3     1      0     0       1       1   \n",
       "2   2  52.0    130     70            3     1      0     0       0       1   \n",
       "3   3  48.0    150    100            1     1      0     0       1       1   \n",
       "4   4  48.0    100     60            1     1      0     0       0       0   \n",
       "\n",
       "    BMI  gender_Men  gender_Women  \n",
       "0  22.0           1             0  \n",
       "1  34.9           0             1  \n",
       "2  23.5           0             1  \n",
       "3  28.7           1             0  \n",
       "4  23.0           0             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('../Labb/data/new_dataset2.csv')\n",
    "df2.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 - Välja modell\n",
    "Välj 3-5 maskininlärningsmodeller, gärna så olika som möjligt. För varje dataset som vi skapade i uppgift 2.3\n",
    "gör följande:\n",
    "\n",
    "- train|validation|test split\n",
    "- skala datasetet med feature standardization och normalization (de görs inte samtidigt, utan i olika omgångar)\n",
    "- definiera hyperparametrar (param_grids) att testa för varje modell\n",
    "- använda GridSearchCV() och välja lämplig evalueringsmetric\n",
    "- gör prediction på valideringsdata\n",
    "- beräkna och spara evaluation score för ditt valda metric\n",
    "- checka bästa parametrarna för respektive modell\n",
    "\n",
    "Vilket dataset väljer du och vilken modell väljer du? Använd den modellen du valt och träna på all data förutom testdatan.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosen models are:\n",
    "- 1. Logistic Regression\n",
    "- 2. KNN \n",
    "- 3. SVM -Support Vector Machines\n",
    "- 4. Random Forest\n",
    "- 5. Gaussian Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For first data df1:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train|validation|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns of first dataframe: (69971, 20)\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows and columns of first dataframe:',df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train1.shape = (55976, 19)\n",
      "X_val1.shape = (11196, 19)\n",
      "X_test1.shape = (2799, 19)\n",
      "y_train1.shape = (55976,)\n",
      "y_val1.shape = (11196,)\n",
      "y_test1.shape = (2799,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from predict_model import split_data\n",
    "\n",
    "# For df1 data train |val|test split data\n",
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = split_data(\n",
    "    df=df1, target_col=\"cardio\",test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"{X_train1.shape = }\\n{X_val1.shape = }\\n{X_test1.shape = }\\n{y_train1.shape = }\\n{y_val1.shape = }\\n{y_test1.shape = }\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- skala datasetet med feature standardization och normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling is standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': Pipeline(steps=[('scaler', StandardScaler()), ('LR', LogisticRegression())]),\n",
       " 'K-Nearest Neighbor': Pipeline(steps=[('scaler', StandardScaler()), ('KNN', KNeighborsClassifier())]),\n",
       " 'Decision Tree': Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                 ('DT', DecisionTreeClassifier())]),\n",
       " 'Random Forest': Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                 ('RF', RandomForestClassifier())]),\n",
       " 'Gaussian Naive Bayes': Pipeline(steps=[('scaling', StandardScaler()), ('NB', GaussianNB())])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_model import scale_features\n",
    "pipelines = scale_features(scale_type='standard')\n",
    "pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define hyperparameters for choosen models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression hyperparameters\n",
    "log_param_grid = [ {'LR__C': [0.01, 0.1, 1, 10, 100], 'LR__penalty': ['l2'], 'LR__solver': ['lbfgs','newton-cg','sag','saga'],'LR__max_iter': [1000, 5000, 10000]}]\n",
    "\n",
    "# KNN hyperparameters\n",
    "knn_param_grid = [{'KNN__n_neighbors': [3, 5, 7, 9, 11], 'KNN__weights': ['uniform', 'distance']}]\n",
    "\n",
    "# Decision Tree hyperparameters\n",
    "tree_param_grid = [{'DT__max_depth': [5, 10, 20], 'DT__min_samples_split': [2, 5, 10]}]\n",
    "\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "forest_param_grid = [{'RF__n_estimators': [10, 50, 100, 200], 'RF__max_depth': [5, 10, 20], 'RF__min_samples_split': [2, 5, 10]}]\n",
    "\n",
    "\n",
    "# GaussianNB hyperparameters\n",
    "Gaussian_param_grid = [{'NB__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Logistic Regression': log_param_grid,\n",
    "    'K-Nearest Neighbor': knn_param_grid,\n",
    "    #'Support vector machines linear': svm_param_grid,\n",
    "    'Decision Tree': tree_param_grid,\n",
    "    'Random Forest': forest_param_grid,\n",
    "    'Gaussian Naive Bayes': Gaussian_param_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "Accuracy Score: 70.41%\n",
      "Best parameters: {'LR__C': 1, 'LR__max_iter': 1000, 'LR__penalty': 'l2', 'LR__solver': 'lbfgs'}\n",
      "=============================================\n",
      "\n",
      "K-Nearest Neighbor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from predict_model import grid_search\n",
    "\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    print('=============================================\\n')\n",
    "    print(f'{model_name:}\\n')\n",
    "    score_file='/results/accuracy_scores.txt'\n",
    "    grid_search(pipeline, param_grid, X_train1, y_train1, X_val1, y_val1,score_file,'dataset1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling is minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': Pipeline(steps=[('scaler', MinMaxScaler()), ('LR', LogisticRegression())]),\n",
       " 'K-Nearest Neighbor': Pipeline(steps=[('scaler', MinMaxScaler()), ('KNN', KNeighborsClassifier())]),\n",
       " 'Decision Tree': Pipeline(steps=[('scaling', MinMaxScaler()), ('DT', DecisionTreeClassifier())]),\n",
       " 'Random Forest': Pipeline(steps=[('scaling', MinMaxScaler()), ('RF', RandomForestClassifier())]),\n",
       " 'Gaussian Naive Bayes': Pipeline(steps=[('scaling', MinMaxScaler()), ('NB', GaussianNB())])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipelines_min = scale_features(scale_type='minmax')\n",
    "pipelines_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "Accuracy Score: 70.40%\n",
      "Best parameters: {'LR__C': 1, 'LR__max_iter': 5000, 'LR__penalty': 'l2', 'LR__solver': 'sag'}\n",
      "==============================================\n",
      "\n",
      "K-Nearest Neighbor\n",
      "\n",
      "Accuracy Score: 68.19%\n",
      "Best parameters: {'KNN__n_neighbors': 11, 'KNN__weights': 'uniform'}\n",
      "==============================================\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "Accuracy Score: 69.43%\n",
      "Best parameters: {'DT__max_depth': 5, 'DT__min_samples_split': 2}\n",
      "==============================================\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Accuracy Score: 70.46%\n",
      "Best parameters: {'RF__max_depth': 10, 'RF__min_samples_split': 10, 'RF__n_estimators': 200}\n",
      "==============================================\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "\n",
      "Accuracy Score: 68.47%\n",
      "Best parameters: {'NB__var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "for model_name, pipeline in pipelines_min.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    print('==============================================\\n')\n",
    "    print(f'{model_name:}\\n')\n",
    "    score_file='/results/accuracy_scores.txt'\n",
    "    grid_search(pipeline, param_grid, X_train1, y_train1, X_val1, y_val1,score_file,'dataset1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For first data df2:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train|validation|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns of second dataframe: (69971, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows and columns of second dataframe:',df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape = (55976, 12)\n",
      "X_val2.shape = (11196, 12)\n",
      "X_test2.shape = (2799, 12)\n",
      "y_train2.shape = (55976,)\n",
      "y_val2.shape = (11196,)\n",
      "y_test2.shape = (2799,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For df1 data train |val|test split data\n",
    "X_train2, X_val2, X_test2, y_train2, y_val2, y_test2 = split_data(\n",
    "    df=df2, target_col=\"cardio\", test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{X_train2.shape = }\\n{X_val2.shape = }\\n{X_test2.shape = }\\n{y_train2.shape = }\\n{y_val2.shape = }\\n{y_test2.shape = }\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling is standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': Pipeline(steps=[('scaler', StandardScaler()), ('LR', LogisticRegression())]),\n",
       " 'K-Nearest Neighbor': Pipeline(steps=[('scaler', StandardScaler()), ('KNN', KNeighborsClassifier())]),\n",
       " 'Decision Tree': Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                 ('DT', DecisionTreeClassifier())]),\n",
       " 'Random Forest': Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                 ('RF', RandomForestClassifier())]),\n",
       " 'Gaussian Naive Bayes': Pipeline(steps=[('scaling', StandardScaler()), ('NB', GaussianNB())])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standad scaling for dataset 2\n",
    "pipelines_stand = scale_features(scale_type='standard')\n",
    "pipelines_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===============================================\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "Accuracy Score: 72.25%\n",
      "Best parameters: {'LR__C': 100, 'LR__max_iter': 1000, 'LR__penalty': 'l2', 'LR__solver': 'saga'}\n",
      " ===============================================\n",
      "\n",
      "K-Nearest Neighbor\n",
      "\n",
      "Accuracy Score: 65.47%\n",
      "Best parameters: {'KNN__n_neighbors': 11, 'KNN__weights': 'distance'}\n",
      " ===============================================\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "Accuracy Score: 73.19%\n",
      "Best parameters: {'DT__max_depth': 5, 'DT__min_samples_split': 2}\n",
      " ===============================================\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Accuracy Score: 73.49%\n",
      "Best parameters: {'RF__max_depth': 10, 'RF__min_samples_split': 10, 'RF__n_estimators': 200}\n",
      " ===============================================\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "\n",
      "Accuracy Score: 59.05%\n",
      "Best parameters: {'NB__var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, pipeline in pipelines_stand.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    print(' ===============================================\\n')\n",
    "    print(f'{model_name:}\\n')\n",
    "    score_file='/results/accuracy_scores.txt'\n",
    "    grid_search(pipeline, param_grid, X_train2, y_train2, X_val2, y_val2,score_file,'dataset2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling is minmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': Pipeline(steps=[('scaler', MinMaxScaler()), ('LR', LogisticRegression())]),\n",
       " 'K-Nearest Neighbor': Pipeline(steps=[('scaler', MinMaxScaler()), ('KNN', KNeighborsClassifier())]),\n",
       " 'Decision Tree': Pipeline(steps=[('scaling', MinMaxScaler()), ('DT', DecisionTreeClassifier())]),\n",
       " 'Random Forest': Pipeline(steps=[('scaling', MinMaxScaler()), ('RF', RandomForestClassifier())]),\n",
       " 'Gaussian Naive Bayes': Pipeline(steps=[('scaling', MinMaxScaler()), ('NB', GaussianNB())])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min max scaling for dataset 2\n",
    "pipelines_max = scale_features(scale_type='minmax')\n",
    "pipelines_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===========================================\n",
      "\n",
      "Logistic Regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, pipeline in pipelines_max.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    print(' ==================================================\\n')\n",
    "    print(f'{model_name:}\\n')\n",
    "    score_file='/results/accuracy_scores.txt'\n",
    "    grid_search(pipeline, param_grid, X_train2, y_train2, X_val2, y_val2,score_file,'dataset2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-learning-tetaV3aO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
